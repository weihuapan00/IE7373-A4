{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IE 7374 Assignment4\n",
    "\n",
    "Weihua Pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# extract text from pdf\n",
    "import fitz\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# data preprocessing\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# for calculate cos similarity\n",
    "from scipy import spatial\n",
    "\n",
    "# openai api \n",
    "import os\n",
    "from openai import OpenAI\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "client = OpenAI()\n",
    "\n",
    "# for counting token\n",
    "import tiktoken\n",
    "\n",
    "# dataframe process pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: \n",
    "Collect relevant data about COVID-19 from Wikipedia and select PDF files containing scientific articles, guidelines, or reports about COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_wiki(url,remove_sup=True):\n",
    "    \"\"\"given wiki url, scrap main content and title\n",
    "\n",
    "    Args:\n",
    "        url (string): url for wiki\n",
    "        remove_sup (bool, optional): remove superscript reference like [123] in the page . Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        String: text output \n",
    "    \"\"\"\n",
    "    \n",
    "    # get URL\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # scrape webpage\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # store wikipedia article\n",
    "    text = \"Article Title: \"\n",
    "\n",
    "    # Get the title of the article\n",
    "    title = soup.find('h1', id='firstHeading').text\n",
    "    text += title + \"\\n\\n\"\n",
    "\n",
    "    # Get Wikipedia's main content\n",
    "    main_content = soup.find('div', id=\"mw-content-text\").find('div', class_=\"mw-parser-output\")\n",
    "\n",
    "    # Remove all <sup> elements to exclude references or superscript texts\n",
    "    if remove_sup:\n",
    "        for sup in main_content.find_all('sup'):\n",
    "            sup.decompose()\n",
    "        \n",
    "    # Include headings and paragraphs\n",
    "    for element in main_content.descendants:\n",
    "        if element.name in ['h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            heading = element.text.strip()\n",
    "            text += '\\n' + heading + '\\n\\n'\n",
    "        elif element.name == 'p':\n",
    "            paragraph = element.text.strip()\n",
    "            text += paragraph + '\\n'\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_pdf(path):\n",
    "    \"\"\"using PyMuPDF to extract text from pdf\n",
    "\n",
    "    Args:\n",
    "        path (string): file path for the pdf\n",
    "    \"\"\"     \n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(path)\n",
    "\n",
    "    # Initialize a variable to hold the extracted text\n",
    "    pdf_text = ''\n",
    "\n",
    "    # Iterate over each page in the PDF\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        # Get the page\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        \n",
    "        # Extract text from the page and add it to the pdf_text variable\n",
    "        pdf_text += page.get_text() + '\\n'\n",
    "\n",
    "    # Close the document\n",
    "    pdf_document.close()\n",
    "\n",
    "    # pdf_text now contains all the text extracted from the PDF\n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://en.wikipedia.org/wiki/COVID-19\")\n",
    "\n",
    "# scrape webpage\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# store wikipedia article\n",
    "text = \"Article Title: \"\n",
    "\n",
    "# Get the title of the article\n",
    "title = soup.find('h1', id='firstHeading').text\n",
    "text += title + \"\\n\\n\"\n",
    "\n",
    "# get Wikipedia's main content \n",
    "main_content = soup.find('div', id=\"mw-content-text\").find('div',class_=\"mw-parser-output\")\n",
    "\n",
    "# Remove all <sup> elements to exclude references or superscript texts\n",
    "for sup in main_content.find_all('sup'):\n",
    "    sup.decompose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: \n",
    "Extract text from the collected sources. For Wikipedia, use web scraping techniques. For PDF files, use PDF parsing libraries like PyMuPDF or PyPDF2 in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_url = [\"https://en.wikipedia.org/wiki/COVID-19\",\n",
    "            \"https://en.wikipedia.org/wiki/COVID-19_pandemic\",]\n",
    "\n",
    "\n",
    "pdf_path = [\"pdf/COVID-19.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the scrape text from wiki to .txt files\n",
    "for i,url in enumerate(wiki_url):\n",
    "    with open(f\"wiki{i}.txt\",mode='w') as text_file:\n",
    "        text_file.write(scrap_wiki(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pdf txt and store in local txt file\n",
    "pdf_txt = extract_text_pdf('pdf/COVID-19.pdf')\n",
    "with open(f'pdf1.txt','w') as file:\n",
    "    file.write(pdf_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    ''' read a txt file by given file path\n",
    "    '''\n",
    "    file = open(file_path, \"r\")\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: \n",
    "Pre-process the extracted text to clean and prepare it for embedding. This includes tasks like removing special characters, stopwords, and stemming or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    \"\"\"\n",
    "    Preprocess the given text using spaCy: tokenize into sentences,\n",
    "    remove stopwords, and apply lemmatization.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The input text to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "    - List of lists: A list of sentences, where each sentence is a list of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    # Process the text with the loaded model\n",
    "    doc = nlp(text.lower().replace('\\n',''))\n",
    "    \n",
    "    # Tokenize the text into sentences and remove stopwords,\n",
    "    # then lemmatize the tokens\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        # Filter out stopwords and punctuation, then lemmatize the rest\n",
    "        tokens = [token.lemma_ for token in sent if not token.is_stop and not token.is_punct]\n",
    "        sentences.append(' '.join(tokens))\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all txt file\n",
    "wiki0 = read_txt('wiki0.txt')\n",
    "wiki1 = read_txt('wiki1.txt')\n",
    "pdf1 = read_txt('pdf1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all document into one list and preprocess them\n",
    "docs = [wiki0,wiki1,pdf1]\n",
    "sentences = [preprocess_data(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Understanding GPT Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1:\n",
    " Study and summarize how GPT and similar transformer models generate embeddings, focusing on representing words and sentences in a high-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Word2Vec: Use neural network to find the embedding vector. Usually can be trained by 2 approach CBOW, skip-gram. \n",
    "* Advantage: Dense embedding vector compare with TF-IDF embedding. Fast and easy to train.\n",
    "* Drawback: Static embedding (same word have one embedding vector), not positional encoding, contextless embedding. Therefore this embedding is not suited for transformer model\n",
    "\n",
    "2. Contextual embedding:\n",
    "    1. initialize token embedding: GPT use sub-word tokenizer, and use BPE(Byte pair encoding)\n",
    "    2. use positional encoding\n",
    "* Advantage: improve Contextual Understanding. able to handle Polysemy. And can do transfer learning (fine-tuning)\n",
    "* Disadvantage: require more computational resource. High complexity, train with more resource and time. Overfiting in small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: \n",
    "Use a pre-trained GPT model (like GPT-2 or GPT-3) from libraries such as Hugging Face’s Transformers to generate embeddings for the pre-processed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   '''Get embedding by GPT model\n",
    "   '''\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Data source','text','embedding'])\n",
    "i = 0\n",
    "for doc_index,doc in enumerate(sentences):\n",
    "    for sent in doc:\n",
    "        df.loc[i] = doc_index , sent, get_embedding(sent)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data source</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>article title covid-19coronavirus</td>\n",
       "      <td>[0.0013947351835668087, -0.05097736418247223, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>disease 2019 covid-19 contagious disease cause...</td>\n",
       "      <td>[0.001791783724911511, -0.04623255878686905, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>know case identify wuhan china december 2019</td>\n",
       "      <td>[-0.05436304956674576, -0.04535301774740219, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>disease quickly spread worldwide result covid-19</td>\n",
       "      <td>[-0.005425873212516308, -0.03965173289179802, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pandemic.the symptom covid‑19 variable include...</td>\n",
       "      <td>[-0.020816093310713768, 0.0005623253528028727,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>2</td>\n",
       "      <td>learn</td>\n",
       "      <td>[-0.007470429874956608, -0.03658827394247055, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2</td>\n",
       "      <td> ask health care provider</td>\n",
       "      <td>[0.006137406919151545, -0.0304762814193964, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2</td>\n",
       "      <td> local state health department</td>\n",
       "      <td>[-0.04278329387307167, -0.013517333194613457, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2</td>\n",
       "      <td> visit website food drug administration fda c...</td>\n",
       "      <td>[0.004667202942073345, -0.04801260679960251, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2</td>\n",
       "      <td> contact center disease control prevention cd...</td>\n",
       "      <td>[0.03313404321670532, -0.07224225997924805, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data source                                               text  \\\n",
       "0              0                  article title covid-19coronavirus   \n",
       "1              0  disease 2019 covid-19 contagious disease cause...   \n",
       "2              0       know case identify wuhan china december 2019   \n",
       "3              0   disease quickly spread worldwide result covid-19   \n",
       "4              0  pandemic.the symptom covid‑19 variable include...   \n",
       "..           ...                                                ...   \n",
       "844            2                                              learn   \n",
       "845            2                          ask health care provider   \n",
       "846            2                     local state health department   \n",
       "847            2   visit website food drug administration fda c...   \n",
       "848            2   contact center disease control prevention cd...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.0013947351835668087, -0.05097736418247223, ...  \n",
       "1    [0.001791783724911511, -0.04623255878686905, -...  \n",
       "2    [-0.05436304956674576, -0.04535301774740219, 0...  \n",
       "3    [-0.005425873212516308, -0.03965173289179802, ...  \n",
       "4    [-0.020816093310713768, 0.0005623253528028727,...  \n",
       "..                                                 ...  \n",
       "844  [-0.007470429874956608, -0.03658827394247055, ...  \n",
       "845  [0.006137406919151545, -0.0304762814193964, 0....  \n",
       "846  [-0.04278329387307167, -0.013517333194613457, ...  \n",
       "847  [0.004667202942073345, -0.04801260679960251, -...  \n",
       "848  [0.03313404321670532, -0.07224225997924805, 0....  \n",
       "\n",
       "[849 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Building the Question-Answering System|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: \n",
    "Implement a search mechanism to find the most relevant text passages to a given query. This can involve calculating similarity scores between the query and document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query : str,\n",
    "           df : pd.DataFrame,\n",
    "           top_n : int,\n",
    "           MODEL : str = \"text-embedding-3-small\",\n",
    "           relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y)):\n",
    "    \"\"\"search top n similar sentences with the query\n",
    "\n",
    "    Args:\n",
    "        query (str): Question\n",
    "        df (pd.DataFrame): dataframe of sentences and its embedding vector\n",
    "        top_n (int): number of sentences you want to get\n",
    "        MODEL (str): name of GPT model\n",
    "        relatedness_fn (_type_, optional): _description_. Defaults to lambdax.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get query embedding\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    \n",
    "    # calculate cos similarity between query and sentences\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # sort by similarity score\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('official death count typically include people die test positive',\n",
       "  'datum estimate true number death covid-19 worldwide include range 18.2 33.5 \\xa0 million ≈27.4 \\xa0 million 18 november 2023 economist 18.5 \\xa0 million 1 april 2023 institute health metric evaluation ≈18.2 \\xa0 million early death 1 january 2020 31 december 2021 comprehensive international study',\n",
       "  'estimate reporting 22.62 total report covid-19 mortality 2020',\n",
       "  '30 october worldwide daily death toll 424 low 385 death report 12 march 2020',\n",
       "  '19 june 2020 country report millionth case nearly 49,000 report death',\n",
       "  '6 march report total worldwide death count surpass 6 \\xa0 million people',\n",
       "  '10 july new york city population 8.4 \\xa0 million 23,377 individual 18,758 confirm 4,619 probable die covid‑19 0.3 population',\n",
       "  'base johns hopkins university statistic global death case ratio 1.02 6,881,955/676,609,955 10 march 2023',\n",
       "  'case report north american country saint kitts nevis confirm case 25 march north american territory bonaire confirm case 16 april.per world datum 103,436,829 confirm case report united states 1,177,223 death country nineteenth high capita worldwide',\n",
       "  'death people condition access medical services.a december 2022 study estimate excess death pandemic 2020 2021 conclude ≈14.8 \\xa0 million excess early death occur reaffirm detail prior calculation update address criticism'),\n",
       " (0.4365763718750244,\n",
       "  0.43256507529890653,\n",
       "  0.42124710667109944,\n",
       "  0.40625766446236056,\n",
       "  0.40167652662332576,\n",
       "  0.3946931201132131,\n",
       "  0.39443386771876043,\n",
       "  0.3871106881070624,\n",
       "  0.3826003101682879,\n",
       "  0.37979818386412445))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"How many people died in US?\",\n",
    "       df,\n",
    "       10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentences with high cos similarity are considered as relevant in embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2:\n",
    " Design a method to extract or generate answers from the selected passages. This could involve fine-tuning a pre-trained model on a question-answering dataset or using heuristic methods to select portions of text as answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query(query:str,\n",
    "                    df: pd.DataFrame,\n",
    "                    max_token:int,\n",
    "                    MODEL= \"text-embedding-3-small\",):\n",
    "    \"\"\" Search relevant content about the question, create query with content for GPT\n",
    "    \"\"\"\n",
    "    text, score = search(query,df,max_token-150,MODEL)\n",
    "    \n",
    "    introduction = 'Use the below information on the COVID-19 to answer the subsequent question. If the answer cannot be found in the information, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    \n",
    "    # iterate top_n sentences given by search(), adding sentences to the query if not exceeding the max_token\n",
    "    for sent in text:\n",
    "        next_sent = f\"\\n\\nSentences on Wikipedia:\\n{sent}\\n\"\n",
    "        if num_tokens(message + next_sent + question,model=MODEL) > max_token:\n",
    "            break\n",
    "        else:\n",
    "            message += next_sent\n",
    "    \n",
    "    return message + question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Evaluation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1:\n",
    "Create a test set of questions about COVID-19 that can be answered using the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many people died in US cause by COVID-19?\",\n",
    "            \"How many people died in the world cause by COVID-19?\",\n",
    "            \"When did the first case of COVID-19 found?\",\n",
    "            \"Where did the first case of COVID-19 found?\",\n",
    "            \"How long does it take to recover from COVID 19?\",\n",
    "            \"What did the first vaccine for COVID-19 come out?\",\n",
    "            \"Which company made the first vaccine?\",\n",
    "            \"Which company made the first vaccine for COVID19?\",\n",
    "            \"How many people around the world are infected with COVID 19\",\n",
    "            \"Where do COVID-19 come from?\",\n",
    "            \"What is the fatality rate of COVID 19\",\n",
    "            \"When is the first person died in US cause by COVID-19?\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query,\n",
    "        df = df,\n",
    "        MODEL= \"gpt-3.5-turbo\",\n",
    "        token_budget = 2000,\n",
    "        print_message=False):\n",
    "        ''' construct query by search relevant content and pass to GPT model.\n",
    "        return GPT's response\n",
    "        '''\n",
    "        # get the query with content\n",
    "        query_with_content = construct_query(query,df,2000)\n",
    "        if print_message:\n",
    "                print(query_with_content)\n",
    "        \n",
    "        # construct messages for GPT model and receive response.\n",
    "        messages = [\n",
    "                {'role':'system','content':'You answer questions about the COVID-19.'},\n",
    "                {\"role\": \"user\", \"content\": query_with_content},\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                temperature=0\n",
    "        )\n",
    "        response_message = response.choices[0].message.content\n",
    "        return query_with_content, response_message\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_content = []\n",
    "GPT_answer = []\n",
    "\n",
    "# put the query_content and GPT's response to the list for troubleshooting\n",
    "for question in questions:\n",
    "    query, answer = ask(question)\n",
    "    query_content.append(query)\n",
    "    GPT_answer.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually collecting answer\n",
    "True_answer =[\"Per Our World in Data, 103,436,829 confirmed cases have been reported in the United States with 1,177,223 deaths, the most of any country,\",\n",
    "             \"estimated 18.2m - 33.5m\",\n",
    "             \"December 2019\",\n",
    "             \"Wuhan, China\",\n",
    "             \"1 week\",\n",
    "             \"Pfizer tested on NOV,2020 and get approved by England on DEC,2020. Base on the event of timeline. This can be inferred.\",\n",
    "             \"Pfizer. Can be inferred.\",\n",
    "             \"Pfizer. Can be inferred.\",\n",
    "             \"As of 14 April 2022, over 500 million cases were confirmed globally.\",\n",
    "             \"Some evidences shows it come from bats\",\n",
    "             \"1.02%\",\n",
    "             \"February 6, 2020.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: \n",
    "Evaluate the system’s performance by measuring the accuracy of its answers against a set of reference answers. Consider metrics like F1 score, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in one dataframe\n",
    "QandA = pd.DataFrame(data= {\"question\": questions,\n",
    "                            \"query_with_content\": query_content,\n",
    "                            \"Actual_answer\": True_answer,\n",
    "                            \"GPT_answer\": GPT_answer\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query_with_content</th>\n",
       "      <th>Actual_answer</th>\n",
       "      <th>GPT_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many people died in US cause by COVID-19?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Per Our World in Data, 103,436,829 confirmed c...</td>\n",
       "      <td>I could not find an answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people died in the world cause by COV...</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>estimated 18.2m - 33.5m</td>\n",
       "      <td>The estimated number of deaths worldwide direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the first case of COVID-19 found?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>December 2019</td>\n",
       "      <td>The first case of COVID-19 was found in Decemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where did the first case of COVID-19 found?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Wuhan, China</td>\n",
       "      <td>The first case of COVID-19 was found in Wuhan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How long does it take to recover from COVID 19?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>1 week</td>\n",
       "      <td>mild cases typically recover within a week, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What did the first vaccine for COVID-19 come out?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Pfizer tested on NOV,2020 and get approved by ...</td>\n",
       "      <td>The first COVID-19 vaccine came out in Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Which company made the first vaccine?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Pfizer. Can be inferred.</td>\n",
       "      <td>I could not find an answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which company made the first vaccine for COVID19?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Pfizer. Can be inferred.</td>\n",
       "      <td>I could not find an answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many people around the world are infected ...</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>As of 14 April 2022, over 500 million cases we...</td>\n",
       "      <td>I could not find an answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where do COVID-19 come from?</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>Some evidences shows it come from bats</td>\n",
       "      <td>COVID-19 is believed to have originated from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the fatality rate of COVID 19</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>1.02%</td>\n",
       "      <td>The fatality rate of COVID-19 is typically mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>When is the first person died in US cause by C...</td>\n",
       "      <td>Use the below information on the COVID-19 to a...</td>\n",
       "      <td>February 6, 2020.</td>\n",
       "      <td>The first person died in the US due to COVID-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0       How many people died in US cause by COVID-19?   \n",
       "1   How many people died in the world cause by COV...   \n",
       "2          When did the first case of COVID-19 found?   \n",
       "3         Where did the first case of COVID-19 found?   \n",
       "4     How long does it take to recover from COVID 19?   \n",
       "5   What did the first vaccine for COVID-19 come out?   \n",
       "6               Which company made the first vaccine?   \n",
       "7   Which company made the first vaccine for COVID19?   \n",
       "8   How many people around the world are infected ...   \n",
       "9                        Where do COVID-19 come from?   \n",
       "10              What is the fatality rate of COVID 19   \n",
       "11  When is the first person died in US cause by C...   \n",
       "\n",
       "                                   query_with_content  \\\n",
       "0   Use the below information on the COVID-19 to a...   \n",
       "1   Use the below information on the COVID-19 to a...   \n",
       "2   Use the below information on the COVID-19 to a...   \n",
       "3   Use the below information on the COVID-19 to a...   \n",
       "4   Use the below information on the COVID-19 to a...   \n",
       "5   Use the below information on the COVID-19 to a...   \n",
       "6   Use the below information on the COVID-19 to a...   \n",
       "7   Use the below information on the COVID-19 to a...   \n",
       "8   Use the below information on the COVID-19 to a...   \n",
       "9   Use the below information on the COVID-19 to a...   \n",
       "10  Use the below information on the COVID-19 to a...   \n",
       "11  Use the below information on the COVID-19 to a...   \n",
       "\n",
       "                                        Actual_answer  \\\n",
       "0   Per Our World in Data, 103,436,829 confirmed c...   \n",
       "1                             estimated 18.2m - 33.5m   \n",
       "2                                       December 2019   \n",
       "3                                        Wuhan, China   \n",
       "4                                              1 week   \n",
       "5   Pfizer tested on NOV,2020 and get approved by ...   \n",
       "6                            Pfizer. Can be inferred.   \n",
       "7                            Pfizer. Can be inferred.   \n",
       "8   As of 14 April 2022, over 500 million cases we...   \n",
       "9              Some evidences shows it come from bats   \n",
       "10                                              1.02%   \n",
       "11                                  February 6, 2020.   \n",
       "\n",
       "                                           GPT_answer  \n",
       "0                         I could not find an answer.  \n",
       "1   The estimated number of deaths worldwide direc...  \n",
       "2   The first case of COVID-19 was found in Decemb...  \n",
       "3   The first case of COVID-19 was found in Wuhan,...  \n",
       "4   mild cases typically recover within a week, wh...  \n",
       "5   The first COVID-19 vaccine came out in Decembe...  \n",
       "6                         I could not find an answer.  \n",
       "7                         I could not find an answer.  \n",
       "8                         I could not find an answer.  \n",
       "9   COVID-19 is believed to have originated from a...  \n",
       "10  The fatality rate of COVID-19 is typically mea...  \n",
       "11  The first person died in the US due to COVID-1...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QandA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many people died in US cause by COVID-19?\n",
      "GPT_answer: I could not find an answer.\n",
      "True_answer: Per Our World in Data, 103,436,829 confirmed cases have been reported in the United States with 1,177,223 deaths, the most of any country,\n",
      "\n",
      "Question: How many people died in the world cause by COVID-19?\n",
      "GPT_answer: The estimated number of deaths worldwide directly caused by COVID-19 ranges from 18.2 to 33.5 million, with an approximate figure of 27.4 million as of November 18, 2023.\n",
      "True_answer: estimated 18.2m - 33.5m\n",
      "\n",
      "Question: When did the first case of COVID-19 found?\n",
      "GPT_answer: The first case of COVID-19 was found in December 2019.\n",
      "True_answer: December 2019\n",
      "\n",
      "Question: Where did the first case of COVID-19 found?\n",
      "GPT_answer: The first case of COVID-19 was found in Wuhan, China in December 2019.\n",
      "True_answer: Wuhan, China\n",
      "\n",
      "Question: How long does it take to recover from COVID 19?\n",
      "GPT_answer: mild cases typically recover within a week, while severe or critical cases may take several weeks to recover.\n",
      "True_answer: 1 week\n",
      "\n",
      "Question: What did the first vaccine for COVID-19 come out?\n",
      "GPT_answer: The first COVID-19 vaccine came out in December 2020.\n",
      "True_answer: Pfizer tested on NOV,2020 and get approved by England on DEC,2020. Base on the event of timeline. This can be inferred.\n",
      "\n",
      "Question: Which company made the first vaccine?\n",
      "GPT_answer: I could not find an answer.\n",
      "True_answer: Pfizer. Can be inferred.\n",
      "\n",
      "Question: Which company made the first vaccine for COVID19?\n",
      "GPT_answer: I could not find an answer.\n",
      "True_answer: Pfizer. Can be inferred.\n",
      "\n",
      "Question: How many people around the world are infected with COVID 19\n",
      "GPT_answer: I could not find an answer.\n",
      "True_answer: As of 14 April 2022, over 500 million cases were confirmed globally.\n",
      "\n",
      "Question: Where do COVID-19 come from?\n",
      "GPT_answer: COVID-19 is believed to have originated from a zoonotic source, likely from wild bats and possibly spread to humans through an intermediary wildlife host.\n",
      "True_answer: Some evidences shows it come from bats\n",
      "\n",
      "Question: What is the fatality rate of COVID 19\n",
      "GPT_answer: The fatality rate of COVID-19 is typically measured using metrics such as the Case Fatality Rate (CFR) or the Infection Fatality Rate (IFR). The Case Fatality Rate (CFR) is the ratio of deaths to diagnosed cases over a specific time interval, while the Infection Fatality Rate (IFR) is the ratio of deaths to the total number of infected individuals, including asymptomatic and undiagnosed cases. The fatality rate can vary by region and population demographics. The IFR for COVID-19 has been estimated to range from 0.24 to 1.49 in different studies.\n",
      "True_answer: 1.02%\n",
      "\n",
      "Question: When is the first person died in US cause by COVID-19?\n",
      "GPT_answer: The first person died in the US due to COVID-19 on January 9, 2020.\n",
      "True_answer: February 6, 2020.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q, a1, a2 in zip(questions,GPT_answer, True_answer):\n",
    "    print(f\"Question: {q}\")\n",
    "    print(f\"GPT_answer: {a1}\")\n",
    "    print(f\"True_answer: {a2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. GPT cannot find the answer, a sentence mentions 1,177,223 deaths in the United America\n",
    "2. GPT retrieve the info successfully\n",
    "3. Correct\n",
    "4. Correct\n",
    "5. Correct\n",
    "6. Correct\n",
    "7. False\n",
    "8. False\n",
    "9. False\n",
    "10. Correct\n",
    "11. False, GPT summaries how to calculate the fatality rate but doesn't provide the exact number.\n",
    "12. Correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use boolean to substitute the answer to calculate the accuracy\n",
    "True_answer_encode = [True] * len(questions)\n",
    "GPT_answer_encode = [False,True,True,True,True,True,False,False,False,True,False,True]\n",
    "QandA['True_answer_encode'] = True_answer_encode\n",
    "QandA['GPT_answer_encode'] = GPT_answer_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         0\n",
      "        True       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weihuapan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/weihuapan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/weihuapan/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(QandA['True_answer_encode'],QandA['GPT_answer_encode']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 58%. F1 score, precision, and recall is not making sense here since we don't false answer in actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Reflection and Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1: \n",
    "Analyze the system's strengths and weaknesses, identifying areas where it performs well and struggles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Advantage: </h4>\n",
    "\n",
    "* You can ask questions that happened after the model is trained.\n",
    "* The search function can find all the relevant passage from embedding vector space. Therefore, we don't need to provide all the information that introduce noise and reduce the number of tokens.\n",
    "\n",
    "\n",
    "<h4>Disadvantage:</h4>\n",
    "\n",
    "* lack of ability to infer the answer. For example, the model is able to know when the first vaccine comes out, but it cannot provide the company that made the vaccine.\n",
    "* It is hard to find out whether GPT use its own knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.2: \n",
    "Propose improvements or alternative approaches to enhance the system's accuracy or efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This can be improved by introduce knowledge graphs to incorporate reasoning.\n",
    "* I should also provide the content source, so I can quickly find where GPT found the information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
